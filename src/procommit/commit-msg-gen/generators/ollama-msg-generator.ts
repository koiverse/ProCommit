
import fetch from "node-fetch";
import { MsgGenerator, buildOllamaGenerateUrl, createDiffAwareUserPrompt, postProcessCommitMessage } from "./msg-generator";
import { getConfiguration } from "@utils/configuration";
import {
  englishInstructions,
  russianInstructions,
  japanInstructions,
  koreanInstructions,
  germanInstructions
} from "@utils/langInstruction";

interface OllamaConfig {
  apiKey?: string; // not used, but for unified interface
  endpoint?: string;
  model?: string;
  temperature?: number;
  maxTokens?: number;
}

export class OllamaMsgGenerator implements MsgGenerator {
  endpoint: string;
  model: string;
  temperature?: number;
  maxTokens?: number;

  constructor(config: OllamaConfig) {
    this.endpoint = config.endpoint || "http://localhost:11434";
    this.model = config.model || "llama3";
    this.temperature = config.temperature;
    this.maxTokens = config.maxTokens;
  }

  async generate(diff: string): Promise<string> {
    const url = buildOllamaGenerateUrl(this.endpoint);
    const config = getConfiguration();
    const language = config.general?.language || "English";
    const includeFileExtension = config.general?.includeFileExtension ?? true;
    let instruction: string;
    switch (language) {
      case "Russian":
        instruction = russianInstructions;
        break;
      case "Japanese":
        instruction = japanInstructions;
        break;
      case "Korean":
        instruction = koreanInstructions;
        break;
      case "German":
        instruction = germanInstructions;
        break;
      case "English":
      default:
        instruction = englishInstructions;
        break;
    }
    const { userPrompt, analysis } = createDiffAwareUserPrompt(diff);
    const prompt = `${instruction}\n\n${userPrompt}`;
    const body: any = {
      model: this.model,
      prompt,
      stream: false,
      options: {}
    };
    if (this.temperature !== undefined) body.options.temperature = this.temperature;
    if (this.maxTokens !== undefined) body.options.num_predict = this.maxTokens;

    const response = await fetch(url, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify(body)
    });
    if (!response.ok) throw new Error(`Ollama API error: ${response.status} ${response.statusText} (${url})`);
    const data: any = await response.json();
    if (!data.response) {
      throw new Error("No commit message generated by Ollama.");
    }
    return postProcessCommitMessage(data.response, { includeFileExtension, analysis });
  }
}
